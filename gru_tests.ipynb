{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pdb\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "\n",
    "# import torch.backends.cudnn as cudnn\n",
    "# cudnn.benchmark = True\n",
    "\n",
    "import math\n",
    "\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_gru_layers=1, bidirectional = True, dropout_p = 0.2):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.h_layers = num_gru_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_gru_layers = num_gru_layers\n",
    "        self.h_layers = num_gru_layers\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.lin_in = hidden_size\n",
    "        if bidirectional:\n",
    "#             self.hidden_size = self.hidden_size* 2\n",
    "            self.h_layers = self.h_layers * 2\n",
    "            self.lin_in = hidden_size * 2\n",
    "        \n",
    "        self.droput = nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers = num_gru_layers, bidirectional = bidirectional, dropout = dropout_p)\n",
    "#         self.out = nn.Sequential(\n",
    "#                                  nn.BatchNorm1d(self.lin_in),\n",
    "#                                  nn.ReLU(True),\n",
    "#                                  nn.Linear(self.lin_in, self.lin_in),\n",
    "#                                  nn.BatchNorm1d(self.lin_in),\n",
    "#                                  nn.ReLU(True),\n",
    "#                                  nn.Linear(self.lin_in, input_size),\n",
    "#                                  torch.nn.LogSoftmax(dim = 1)\n",
    "#                                 )\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "#         output = self.droput(input)\n",
    "        \n",
    "        output, hidden = self.gru(input, hidden)        \n",
    "#         output = torch.cat([torch.unsqueeze(self.out(out_batch),0) for out_batch in output],0)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size = 1):\n",
    "        result = Variable(torch.zeros(self.h_layers, batch_size, self.hidden_size))\n",
    "        \n",
    "        return result\n",
    "#         if use_cuda:\n",
    "#             return result.cuda()\n",
    "#         else:\n",
    "#             return result\n",
    "  \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, attn_in_size, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "#         self.attn = nn.Linear(attn_in_size*2, hidden_size)\n",
    "        \n",
    "        self.attn = nn.Sequential(\n",
    "                                    nn.Linear(attn_in_size*2, hidden_size)\n",
    "                                )\n",
    "        \n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "        stdv = 1. / math.sqrt(self.v.size(0))\n",
    "        self.v.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        timestep = encoder_outputs.size(0)\n",
    "        h = hidden.repeat(timestep, 1, 1).transpose(0, 1)\n",
    "        encoder_outputs = encoder_outputs.transpose(0, 1)  # [B*T*H]\n",
    "        attn_energies = self.score(h, encoder_outputs)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        # [B*T*2H]->[B*T*H]\n",
    "#         pdb.set_trace()\n",
    "        \n",
    "#         energy = torch.cat([torch.unsqueeze(self.attn(out_batch),0) for out_batch in torch.cat([hidden, encoder_outputs], 2)],0)\n",
    "        \n",
    "        energy = self.attn(torch.cat([hidden, encoder_outputs], 2))\n",
    "        \n",
    "        energy = energy.transpose(1, 2)  # [B*H*T]\n",
    "        v = self.v.repeat(encoder_outputs.size(0), 1).unsqueeze(1)  # [B*1*H]\n",
    "        energy = torch.bmm(v, energy)  # [B*1*T]\n",
    "        return energy.squeeze(1)  # [B*T]\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, n_layers=1,  bidirectional = True, dropout_p=0.2):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        output_size = embed_size\n",
    "        \n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        \n",
    "        self.hidden_in = hidden_size\n",
    "        if bidirectional:\n",
    "            self.hidden_in = hidden_size * 2\n",
    "\n",
    "        self.embed = nn.Embedding(output_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout_p, inplace=True)\n",
    "        self.attention = Attention(self.hidden_in, hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_in + embed_size, hidden_size, n_layers, bidirectional = bidirectional)\n",
    "#         self.out = nn.Linear(self.hidden_in * 2, output_size)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "                                    nn.Linear(self.hidden_in * 2, output_size)\n",
    "                                )\n",
    "\n",
    "    def forward(self, embedded, last_hidden, encoder_outputs):\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "#         embedded = self.embed(input).unsqueeze(0)  # (1,B,N)\n",
    "#         embedded = self.dropout(input)\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "\n",
    "        \n",
    "        h_in = last_hidden[-1]\n",
    "        if self.bidirectional:\n",
    "            h_in = torch.cat([last_hidden[-2], last_hidden[-1]], 1)\n",
    "        \n",
    "        attn_weights = self.attention(h_in, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (B,1,N)\n",
    "        context = context.transpose(0, 1)  # (1,B,N)\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat([embedded, context], 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "#         output = output.squeeze(0)  # (1,B,N) -> (B,N)\n",
    "#         context = context.squeeze(0)\n",
    "        \n",
    "        output = self.out(torch.cat([output, context], 2))\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbf517597074e238696957d16b56ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AAALLLLLLLLLLLL\n",
      "MATVLLALLVYLGAL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dc4b4276d942c1b243062c9d320565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YVLCTVLLAVLLLVA\n",
      "YVLCTVLLALAVLLA\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79aedaa5a4bf47a5ba0184f569adf830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DMYSGIIRRLLKLAV\n",
      "MDYSRIIERLLKLAV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea1ede63bb24ea5bb81ffe620cad830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WRALHPLLLLLLLFP\n",
      "WRALHPLLLLLLLFP\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635ef3a978a84f1088d6605c0c546b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KSKNVFLKNNLKKIGDGGVS\n",
      "KSKNVFLKNNLLKIGDFGVS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbcf3d19acf4d2b9577d9165fc2631f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QALIDALLEEDGKKLLCVSS\n",
      "QALIDACLEEDGKLYLCVSS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c74c15606d489ca5e8a0f2db619727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=325), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QYLRLSHNELADSGIPGNSSNVSSL\n",
      "QYLRLSHNELADSGIPGNSFNVSSL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911af13d6aa24406800b94fc3d1042e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=325), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VSSCERGLVKVWHIAMAQLVKTLSG\n",
      "VSSCERGLVKVWHIAMAQLVKTLSG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ea77dc163f4387870d03387927010b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=325), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SFDSSPTSSTDGGSSYGLDSGFCTI\n",
      "SFDSSPTSSTDGHSSYGLDSGFCTI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7758803f24f94e738fd78b95025cc0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=331), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVGRPSPASSGRRESGPPGRRHEHSQHPQS\n",
      "SVGRPSPLASGRRESGAPHRRHEHSPHPQS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bba23e37a3748b3bb4547125eaeb29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=331), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IRGKIRLRQASWIIRGGTEADYMLHNVQVI\n",
      "IRGKIRLRQASWIIRGGTEADYQLHNVQVI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fbe6b718e14855849a0788a4b4bcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=331), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AEPCGKGHRDCNSPGSFRCECKTGYYGDGI\n",
      "AEPCGKGHRCVNSPGSFRCECKTGYYFDGI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92a707927f1418a9c4755514303f7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=336), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VLLSEEEIQQTCEMLQQCEEEFIIIISGGKPLVVE\n",
      "VLLSEEEIQQTCEMLQQCKEEFINDISGGKPLEVE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e75063ce7d84475b9f81ec7944245d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=336), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VRGFLEKESAAVSRPLNPFTAKALSGTSPDVDQPG\n",
      "VRGFLEKESAIVSRPLNPFTAKALSGTSPDDVQPG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf775be532440b6b5555bf57c388e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=336), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VVLSFSRIAIILPANNSFGPLIISLGRTVKDIFKF\n",
      "VVLSFSRIAYILPANESFGPLQISLGRTVKDIFKF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34d535d27aa4a039000019d3359bd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=336), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "YSFDLMLSITSIFHLCSVAIDRFYAICIYYLLSTK\n",
      "YSFDLMLSITSIFHLCSVAIDRFYAICYPLLYSTK\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bfd32c2f89436d9c99673fc1bb8157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=342), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HSVEEELTSVIGINKKIPPFISKGEIMNEWCFFTCLVSFS\n",
      "HSVMEELTSVIGINMKIPPFISKGEIMNEWFHFTCLVSFS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bbee0d9c4c43239d4a9f3bebc8717c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=342), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RYLVTSLILVVTMAILCCSMQDCVRSKPPLWLLGLVTISL\n",
      "RYLVTSLILVVTMAILCCSMQDCVRSKPWLGLLGLVTISL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aecb27e26a94eacb7f885b41bba650a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=342), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RRGRPGLKGQEGPPGAPGIRTGIQGLKGDQGEPGPSGNPG\n",
      "RRGRPGLKGEQGEPGAPGIRTGIQGLKGDQGEPGPSGNPG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d89befb0954f19b03e4efe2246ded2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=342), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PTLAPAASVAAAFQFQLLVMQPCGAADEAAAPGSGVGAGK\n",
      "PTLAPASVAAAASQFTLLVMQPCAGQDEAAAPGGSVGAGK\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ae0552bed848bc919e4467eb1dc4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=342), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFIVLCHPDTIRSITAASAAIAPKDNLFFRFLKPWLGEGI\n",
      "PFIVLCHPDTIRSITNASAAIAPKDNLFIRFLKPWLGEGI\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99734b4db54348b6b83c543b578fc306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=348), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EKRLEEEQLLAEEEDDDLKETTDLRKIAAQLLQQEQKNRILNHST\n",
      "EKRLEKEQLLAEEEDDDLKEVTDLRKIAAQLLQQEQKNRILNHST\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a0f4f203c34d7fa21ef327f8c076d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=348), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GVLENWIWQMVAALQSKAPQPVNVVLVDNITLAHHHYTIAVRNTR\n",
      "GVLENWIWQMVAALKSQPAQPVNVGLVDWITLAHDHYTIAVRNTR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82589b94c81e4464be16955cd9278aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=348), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ISRENGGSSSILYYRPFEKLRMSDDGGIRNLYLDFGGPEGEDTMD\n",
      "ISRENGGSSSILYRYPFERLKMSADDGIRNLYLDFGGPEGELTMD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54b0c965b804578b9159fcdd6eaa5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=348), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERNEILTEEQNFSQDVTLNSLVSEAFVRFFVELGGHYSLMMTVTE\n",
      "ERNEILTQEQNFSQDVTLNSLVSEAFVRFFVELVGHYSLNMTVTE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b5f625b6ad4cc8801319751cb34f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=348), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASLSGEREFKTPTISLKETIGKYSDDHEMRENVYHRKIISWFGDS\n",
      "ASLSGEREFKTPTISLKETIGKYSDDHEMRNEVYHRKIISWFGDS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65a4d9896064662a6ddb183e0777753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=348), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PHAAAAAAAAAAAAVEASSPWSGSAVGMAGSPQQPPQPPPPPPQG\n",
      "PHAAAAAAAAAAAAVEASSPWSGSAVGMAGSPQQPPQPPPPPPQG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea53f486d0a74af3a10e80996843ee2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AEAVRPKTPPVVIKSQQTKKEDEEEISTSPGVSSFVDSAFCADDLDQEDL\n",
      "AEAVRPKTPPVVIKSQLKTQEDEEEISTSPGVSEFVSDAFDACNLNQEDL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f29445ea5a4880a32f680baeeeced5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCGSNCGQSSSCAPVYCRRTCYYPTTVCLPGCLNQSGGSNCCQCPCCRPC\n",
      "SCGSSCGQSSSCAPVYCRRTCYYPTTVCLPGCLNQSCGSNCCQPCCRPAC\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bb928c4c43462fb4ecd0548d477abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ENRHGGGLTGLNKAETAAKHGEAQVKIWRRSYDVPPPPMEPDHPFYSNIS\n",
      "NERHYGGLTGLNKAETAAKHGEAQVKIWRRSYDVPPPPMEPDHPFYSNIS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e03590cbd1048e7b71f86db835e8b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QPSNLLPQRGLGAPLPAETAHTPQSPNDRSLYLSPKSSSASSSLHARQSP\n",
      "QPSNLLPQRGLGAPLPAETAHTQPSPNDRSLYLSPKSSSASSSLHARQSP\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bcc4bf88da400faacd6904e4ea10de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AELEVRVAAVVDTHLEEAGGGPEPTRNGVDPPPRRAAASVPPGSTRLLLP\n",
      "AELVERVAAIDVTHLEEADGGPEPTRNGVDPPPRARAASVIPGSTSRLLP\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26775ad7c1524a8d9dd900007410105a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GCGRLLRGLLAAPAATSWSRLPARGFREVVETEQGKTTIIEGRITATPKE\n",
      "GCGRLLRGLLAGPAATSWSRLPARGFREVVETQEGKTTIIEGRITATPKE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e723a76991c94c3db7c238e8559678ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETANLDGETNIKIRQGLSHTAMDQTRDVLMKLSGTIECEGPNRHLYDFTG\n",
      "ETANLDGETNLKIRQGLSHTADMQTREVLMKLSGTIECEGPNRHLYDFTG\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65df626200c64b9594d26a3f4949e7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=354), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VCVCQHNTAGPNCERCAPFYNNRPWRPAAGQDAHECQRCDCGGHSETCHF\n",
      "VCVCQHNTAGPNCERCAPFYNNRPWRPAEGQDAHECQRCDCNGHSETCHF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432fc652a35349708a5a2cceb288738c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=360), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from decimal import Decimal\n",
    "\n",
    "import seq2loc.utils as utils\n",
    "\n",
    "from seq2loc.data.datasets import PaddedSequenceDataset, SequenceDataset\n",
    "\n",
    "\n",
    "\n",
    "GPU_id = 0\n",
    "LR = 0.001\n",
    "N_EPOCHS = 500\n",
    "hidden_size = 128\n",
    "batch_size = 64\n",
    "num_gru_layers = 3\n",
    "teacher_forcing_ratio = 0.5\n",
    "log_number = 50\n",
    "loss_thresh = 1.5E-4\n",
    "N_LETTERS = utils.n_letters()\n",
    "\n",
    "grad_clip = 10.0\n",
    "\n",
    "bidirectional=True\n",
    "\n",
    "ds = PaddedSequenceDataset(SequenceDataset('./data/uniprot.tsv', max_seq_len = 15), GPU_id = GPU_id)\n",
    "\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "enc = EncoderRNN(N_LETTERS, hidden_size, num_gru_layers, bidirectional=bidirectional).cuda(GPU_id)\n",
    "dec = DecoderRNN(N_LETTERS, hidden_size, num_gru_layers, bidirectional=bidirectional).cuda(GPU_id)\n",
    "\n",
    "\n",
    "opt = optim.Adam([{'params':enc.parameters()}, {'params':dec.parameters()}], lr = LR)\n",
    "\n",
    "# dec = enc\n",
    "\n",
    "losses = np.array([])\n",
    "\n",
    "for _ in range(N_EPOCHS):\n",
    "\n",
    "    \n",
    "    loss_thresh = 8.12E-04 / np.log(ds.sequenceDataset.max_seq_len)\n",
    "    epoch_inds = utils.get_epoch_inds(len(ds), batch_size)\n",
    "    pbar = tqdm(epoch_inds)\n",
    "\n",
    "    epoch_losses = list()\n",
    "    \n",
    "    for batch in pbar:\n",
    "        opt.zero_grad()\n",
    "\n",
    "        x, x_inds = ds[batch]        \n",
    "#         x = (x - 1) * log_number #set to log(one-hot)\n",
    "\n",
    "        hidden = enc.initHidden(batch_size).cuda(GPU_id)\n",
    "\n",
    "        enc_out, hidden = enc(x, hidden)\n",
    "        \n",
    "        #input the stop character to the stream    \n",
    "        out = Variable(utils.stopChar(batch_size)).cuda(GPU_id)\n",
    "\n",
    "        loss = Variable(torch.zeros(1,1,1).cuda(GPU_id))\n",
    "\n",
    "        out_list = list()\n",
    "        for i in range(x.shape[0]):\n",
    "\n",
    "            out, hidden, attn_weights = dec(out.detach(), hidden, enc_out)    \n",
    "            \n",
    "            out_list += [out]\n",
    "\n",
    "            loss += criterion(torch.squeeze(out,0), x_inds[i])\n",
    "    \n",
    "            if teacher_forcing_ratio < torch.rand(1):\n",
    "                out = torch.unsqueeze(x[i],0)\n",
    "            else:\n",
    "#                 pdb.set_trace()\n",
    "                out = utils.indicesToTensor(torch.max(out,2)[1].cpu(), ndims = N_LETTERS)\n",
    "                out = Variable(out).cuda(GPU_id)\n",
    "                \n",
    "\n",
    "\n",
    "        loss = loss/(x.shape[0]*x.shape[1]*x.shape[2])\n",
    "        loss.backward()\n",
    "        \n",
    "        clip_grad_norm(enc.parameters(), grad_clip)\n",
    "        clip_grad_norm(dec.parameters(), grad_clip)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        losses_np = np.squeeze(loss.detach().cpu().numpy())\n",
    "        \n",
    "        epoch_losses += [losses_np]\n",
    "    #     t.set_description('GEN %i' % i)\n",
    "        pbar.set_description('%.4E' % Decimal(str(losses_np)))\n",
    "        \n",
    "    losses = np.hstack([losses, np.stack(epoch_losses)])\n",
    "    \n",
    "    if np.mean(epoch_losses) < loss_thresh:\n",
    "        ds.sequenceDataset.max_seq_len += 5\n",
    "        \n",
    "        if batch_size > 2:\n",
    "            batch_size -= 1\n",
    "    \n",
    "    pbar.set_description('%.4E' % Decimal(str(np.mean(epoch_losses))))\n",
    "    \n",
    "    print(''.join(utils.tensorToChar(torch.cat(out_list, 0))[:,0]))\n",
    "    print(''.join(utils.tensorToChar(x)[:,0]))\n",
    "    \n",
    "    if '.' in ''.join(utils.tensorToChar(x)[:,0]):\n",
    "        pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'embedded' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5c836950a677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mout_list\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-19712b221a55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Get the embedding of the current input word (last output word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;31m#         embedded = self.embed(input).unsqueeze(0)  # (1,B,N)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m# Calculate attention weights and apply to encoder outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#         pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'embedded' referenced before assignment"
     ]
    }
   ],
   "source": [
    "dec.train(False)\n",
    "enc.train(False)\n",
    "\n",
    "\n",
    "x, x_inds = ds[epoch_inds[0]]\n",
    "        \n",
    "x = (x - 1) * log_number\n",
    "\n",
    "hidden = enc.initHidden(batch_size).cuda(GPU_id)\n",
    "\n",
    "#     pbar.set_description(str(x.shape[0]))\n",
    "\n",
    "enc_out, hidden = enc(x, hidden)\n",
    "\n",
    "#input the stop character to the stream    \n",
    "out = (Variable(utils.stopChar(batch_size)).cuda(GPU_id)-1) * log_number\n",
    "\n",
    "loss = Variable(torch.zeros(1,1,1).cuda(GPU_id))\n",
    "\n",
    "out_list = list()\n",
    "#     pdb.set_trace()\n",
    "for i in range(x.shape[0]):\n",
    "\n",
    "    out, hidden = dec(out, hidden, enc_out)    \n",
    "\n",
    "    out_list += [out]\n",
    "\n",
    "    loss += criterion(torch.squeeze(out,0), x_inds[i])\n",
    "\n",
    "x_hat = utils.tensorToChar(torch.cat(out_list, 0))\n",
    "x = utils.tensorToChar(x)\n",
    "\n",
    "print(''.join(x_hat[:,2]))\n",
    "print(''.join(x[:,2]))\n",
    "\n",
    "enc.train(True)\n",
    "dec.train(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11307868530700314"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.exp(3.219125824868201)/28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLMVVSMACVGFFLLEGPW\n",
      "MMHCTPCLLLMMMMMMMMMM\n"
     ]
    }
   ],
   "source": [
    "enc.train(False)\n",
    "dec.train(False)\n",
    "\n",
    "x_tmp, _ = ds[[np.random.randint(len(ds))]]\n",
    "\n",
    "# x = torch.unsqueeze(x[:,0,:],1)\n",
    "batch_size_tmp = x_tmp.shape[1]\n",
    "\n",
    "hidden = enc.initHidden(batch_size_tmp).cuda(GPU_id)\n",
    "out, hidden = enc(x_tmp, hidden)\n",
    "\n",
    "#input the stop character to the stream    \n",
    "out = Variable(stopChar(batch_size_tmp)).cuda(GPU_id)\n",
    "\n",
    "\n",
    "#     pdb.set_trace()\n",
    "out_chars = list()\n",
    "\n",
    "for i in range(x_tmp.shape[0]):\n",
    "\n",
    "    out, hidden = dec(out, hidden) \n",
    "    \n",
    "    out_chars += [tensorToChar(out)[0,0]]\n",
    "    \n",
    "enc.train(True)\n",
    "dec.train(True)\n",
    "\n",
    "print(''.join(np.hstack(tensorToChar(x_tmp))))\n",
    "print(''.join(out_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008124150603306629"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3E-4*np.log(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.499953655676149e-05"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6.77e-05/np.log(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
